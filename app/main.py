import os
import re
from typing import List, Annotated, TypedDict, Literal, Any, Dict
from contextlib import asynccontextmanager

from fastapi import FastAPI
from pydantic import BaseModel, Field
import uvicorn

from langchain_ollama import ChatOllama
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, BaseMessage
from langchain_core.runnables import RunnableConfig
from langchain_core.tools import tool
from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser

from langgraph.graph import END, StateGraph, START
from langgraph.graph.message import add_messages
from langgraph.checkpoint.memory import MemorySaver
from langgraph.prebuilt import ToolNode, tools_condition

from langchain_community.vectorstores import FAISS
from langchain_community.utilities import SQLDatabase
from dotenv import load_dotenv
from opc_client import IgnitionOpcClient

# ----------------------------
# [0] ì„¤ì • ë° ì´ˆê¸°í™”
# ----------------------------
load_dotenv()

EMBEDDING_MODEL_NAME = "intfloat/multilingual-e5-large"
DB_PATH = "./faiss_index"
LLM_MODEL_NAME = "llama3.1"

OPC_ENDPOINT = os.getenv("OPC_ENDPOINT", "opc.tcp://localhost:62541")
opc_client = IgnitionOpcClient(OPC_ENDPOINT)

SQL_HOST = os.getenv("SQL_HOST", "127.0.0.1")
SQL_PORT = int(os.getenv("SQL_PORT", "3306"))
SQL_USER = os.getenv("SQL_USER", "ignition")
SQL_PASSWORD = os.getenv("SQL_PASSWORD", "password")
SQL_DB = os.getenv("SQL_DB", "ignition")

global_retriever = None


def build_db_uri() -> str:
    return f"mysql+pymysql://{SQL_USER}:{SQL_PASSWORD}@{SQL_HOST}:{SQL_PORT}/{SQL_DB}"


sql_db = SQLDatabase.from_uri(build_db_uri())


# ----------------------------
# [1] ë„êµ¬ ì •ì˜ (Tools)
# ----------------------------
# --- 1. OPC UAìš© ë„êµ¬ ---
@tool
async def read_ignition_tag(tag_path: str):
    """
    Ignition SCADAì˜ íƒœê·¸ ê°’ì„ ì½ìŠµë‹ˆë‹¤.
    'í˜„ì¬ ì˜¨ë„ ì•Œë ¤ì¤˜', 'ìƒíƒœ í™•ì¸í•´ì¤˜' ê°™ì€ ì§ˆë¬¸ì— ì‚¬ìš©í•˜ì„¸ìš”.

    Args:
        tag_path: ì½ì„ íƒœê·¸ì˜ ì „ì²´ ê²½ë¡œ (ì˜ˆ: '[default]Tank/Temperature')
    """
    print(f"ğŸ› ï¸ [Tool] íƒœê·¸ ì½ê¸° ì‹œë„: {tag_path}")
    return await opc_client.read_tag(tag_path)


@tool
async def write_ignition_tag(tag_path: str, value: str):
    """
    Ignition SCADAì˜ íƒœê·¸ì— ê°’ì„ ì”ë‹ˆë‹¤(ì œì–´).
    'ì„¤ì •ê°’ì„ 50ìœ¼ë¡œ ë°”ê¿”', 'ëª¨í„° ì¼œ' ê°™ì€ ëª…ë ¹ì— ì‚¬ìš©í•˜ì„¸ìš”.

    Args:
        tag_path: ì“¸ íƒœê·¸ì˜ ì „ì²´ ê²½ë¡œ (ì˜ˆ: '[default]Tank/Setpoint')
        value: ë³€ê²½í•  ê°’ (ìˆ«ìë‚˜ ë¬¸ìì—´)
    """
    print(f"ğŸ› ï¸ [Tool] íƒœê·¸ ì“°ê¸° ì‹œë„: {tag_path} -> {value}")
    return await opc_client.write_tag(tag_path, value)


# ì‚¬ìš©í•  ë„êµ¬ ëª©ë¡
chat_tools_list = [read_ignition_tag, write_ignition_tag]


# --- 2. SQLìš© (ì´ë ¥/DB) - ì»¤ìŠ¤í…€ ë„êµ¬ ---
@tool
def db_list_tables():
    """DBì˜ ëª¨ë“  í…Œì´ë¸” ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
    try:
        return sql_db.get_table_names()
    except Exception as e:
        return f"Error: {e}"


@tool
def db_get_schema(table_names: str):
    """íŠ¹ì • í…Œì´ë¸”ì˜ ìŠ¤í‚¤ë§ˆ(ì»¬ëŸ¼ ì •ë³´)ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤. (ì…ë ¥: 'table1, table2')"""
    try:
        if isinstance(table_names, list):
            table_names = ", ".join(table_names)
        return sql_db.get_table_info(table_names.split(","))
    except Exception as e:
        return f"Error: {e}"


@tool
def db_query(query: str):
    """SQL SELECT ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤. ë°˜ë“œì‹œ LIMITë¥¼ í¬í•¨í•˜ì„¸ìš”."""
    try:
        if any(x in query.lower() for x in ["update", "delete", "drop", "insert"]):
            return "Error: Read-only allowed."
        return sql_db.run(query)
    except Exception as e:
        return f"SQL Error: {e}"


sql_tools_list = [db_list_tables, db_get_schema, db_query]


# ----------------------------
# [2] Lifespan
# ----------------------------
@asynccontextmanager
async def lifespan(app: FastAPI):
    global global_retriever
    print("\n[System] ì„œë²„ ì´ˆê¸°í™” ì¤‘...")
    try:
        embeddings = HuggingFaceEmbeddings(
            model_name=EMBEDDING_MODEL_NAME,
            model_kwargs={"device": "cpu"},
            encode_kwargs={"normalize_embeddings": True},
        )
        if os.path.exists(DB_PATH):
            vectorstore = FAISS.load_local(
                DB_PATH, embeddings, allow_dangerous_deserialization=True
            )
            global_retriever = vectorstore.as_retriever(search_kwargs={"k": 5})
            print("[System] ë²¡í„° DB ë¡œë“œ ì™„ë£Œ.")
        else:
            print("[System] DB ì—†ìŒ. RAG ì œí•œë¨.")
    except Exception as e:
        print(f"[Warning] ë²¡í„° DB ì‹¤íŒ¨: {e}")
    yield
    print("[System] ì„œë²„ ì¢…ë£Œ")


app = FastAPI(title="Ignition Agent", lifespan=lifespan)


# ----------------------------
# [3] Router (í‚¤ì›Œë“œ ì œê±° -> LLM íŒë‹¨)
# ----------------------------


# ë¼ìš°íŒ… ì¹´í…Œê³ ë¦¬ ì •ì˜
class RouteResponse(BaseModel):
    destination: Literal["sql_search", "rag_search", "chat"] = Field(
        description="The target agent to route the user request to."
    )


class GraphState(TypedDict):
    messages: Annotated[List[BaseMessage], add_messages]
    intent_category: str  # intent_categoryë§Œ ë‚¨ê¹€ (type/payload ë“± ë³µì¡í•œê±° ì œê±°)
    payload: str
    documents: List[Document]


# ----------------------------
# [4] Node Functions
# ----------------------------


def intent_router(state: GraphState):
    """
    [í•µì‹¬] LLMì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ìì˜ ì˜ë„ë¥¼ 3ê°€ì§€ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤.
    - sql_search: DB, ì—­ì‚¬, í†µê³„, ë¡œê·¸
    - rag_search: ë§¤ë‰´ì–¼, ì§€ì‹, ì •ì˜, ë°©ë²•
    - chat: ì‹¤ì‹œê°„ ê°’ ì¡°íšŒ, ì œì–´, ì¼ë°˜ ëŒ€í™”
    """
    print("ğŸš¦ [Router] ì˜ë„ ë¶„ë¥˜ ì¤‘...")
    question = state["messages"][-1].content

    llm = ChatOllama(model=LLM_MODEL_NAME, temperature=0, format="json")

    # ë¶„ë¥˜ í”„ë¡¬í”„íŠ¸
    prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                """You are a smart router. Classify the user question into one of three categories:
        
        1. 'sql_search': Questions about **historical data**, trends, logs, averages, past events, or database queries. (e.g., "What was the average RPM yesterday?", "Show error logs from last week")
        2. 'rag_search': Questions asking for **definitions, manuals, troubleshooting guides, specifications**, or general knowledge. (e.g., "What is a Chiller?", "How to fix Error 505?", "Explain the pump structure")
        3. 'chat': Requests for **real-time values**, **control commands**, greetings, or general chat. (e.g., "What is the current temperature?", "Turn on the motor", "Hi there")

        Return ONLY a JSON object: {{"destination": "sql_search" | "rag_search" | "chat"}}
        """,
            ),
            ("human", "{question}"),
        ]
    )

    chain = prompt | llm | JsonOutputParser()

    try:
        result = chain.invoke({"question": question})
        destination = result.get("destination", "chat")
    except:
        destination = "chat"  # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’

    print(f"ğŸš¦ [Router] Decision: {destination}")

    return {
        "intent_category": destination,
        "payload": question,  # payloadëŠ” ê·¸ëŒ€ë¡œ ì§ˆë¬¸ ë‚´ìš©
    }


def retrieve_rag(state: GraphState):
    if not global_retriever:
        return {"documents": []}
    return {"documents": global_retriever.invoke(state["payload"])}


def generate_rag(state: GraphState):
    # ì‹¤ì œ êµ¬í˜„ ì‹œì—ëŠ” ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ LLM ë‹µë³€ ìƒì„± í•„ìš”
    context = "\n".join([d.page_content for d in state.get("documents", [])])
    return {
        "messages": [AIMessage(content=f"[RAG ê²°ê³¼]\nì°¸ê³ ë¬¸ì„œ:\n{context[:200]}...")]
    }


def generate_chat(state: GraphState):
    llm = ChatOllama(model=LLM_MODEL_NAME, temperature=0.1)
    llm_with_tools = llm.bind_tools(chat_tools_list)
    system_msg = SystemMessage(
        content="You are an Ignition SCADA Operator. Answer in Korean."
    )
    response = llm_with_tools.invoke([system_msg] + state["messages"])
    return {"messages": [response]}


def sql_generate(state: GraphState):
    """
    SQL ì‹¤í–‰ ë° ê²°ê³¼ ìš”ì•½ ì—ì´ì „íŠ¸
    """
    llm = ChatOllama(model=LLM_MODEL_NAME, temperature=0)
    llm_with_tools = llm.bind_tools(sql_tools_list)

    # [í•µì‹¬ ìˆ˜ì •] Ignition DB êµ¬ì¡°ë¥¼ 'ê°•ì œë¡œ' ì£¼ì…í•˜ëŠ” í”„ë¡¬í”„íŠ¸
    system_msg = SystemMessage(
        content=(
            "You are an expert on **Ignition Historian Databases (MariaDB)**.\n"
            "This database uses a specific schema where Tag Names and Data are separated.\n"
            "You must follow the **Strict Execution Path** below. Do NOT guess table names.\n\n"
            "### ğŸ—ºï¸ Database Structure Map (READ CAREFULLY)\n"
            "1. **`sqlth_te` Table**: Contains Tag Definitions.\n"
            "   - Columns: `id` (Tag ID), `tagpath` (Tag Name)\n"
            "   - Usage: Query this table FIRST to convert a Tag Name (e.g., 'FAN1') into an `id`.\n"
            "2. **`sqlt_data_X_YYYY_MM` Tables**: Contains History Data (Partitioned by Month).\n"
            "   - Example: `sqlt_data_1_2026_01` (Data for Jan 2026)\n"
            "   - Columns: `tagid` (Foreign Key), `intvalue`, `floatvalue`, `t_stamp` (Unix Timestamp)\n"
            "   - Usage: Query this table SECOND using the `tagid` found in step 1.\n\n"
            "### ğŸ›£ï¸ Strict Execution Path\n"
            "When the user asks: 'Get average RPM of FAN1 on 2026-01-18':\n"
            "1. **Call `db_list_tables()`**: Find the partition table that matches the target date (look for `_2026_01`).\n"
            "2. **Call `db_query()` on `sqlth_te`**: Find the ID for the tag.\n"
            "   - Query: `SELECT id, tagpath FROM sqlth_te WHERE tagpath LIKE '%FAN1%'`\n"
            "3. **Call `db_query()` on partition table**: Use the `id` from Step 2 to get data.\n"
            "   - Query: `SELECT AVG(floatvalue) FROM sqlt_data_1_2026_01 WHERE tagid = [FOUND_ID] AND t_stamp BETWEEN ...`\n"
            "4. **Final Answer**: Summarize in Korean.\n\n"
            "**ğŸš« PROHIBITED ACTIONS:**\n"
            "- NEVER try `SELECT ... FROM FAN1`. 'FAN1' is a value in `tagpath`, NOT a table name.\n"
            "- NEVER skip `db_list_tables()`. You don't know which partition index (1, 5, etc.) exists for the date.\n"
        )
    )

    # ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ í¬í•¨
    messages = [system_msg] + state["messages"]

    response = llm_with_tools.invoke(messages)
    return {"messages": [response]}


async def exec_tag_read(state: GraphState):
    # Chatì—ì„œ Toolì„ í˜¸ì¶œí•˜ë©´ ì´ìª½ìœ¼ë¡œ ì˜¬ ìˆ˜ë„ ìˆê³ , Chat Loop ë‚´ì—ì„œ ì²˜ë¦¬ë  ìˆ˜ë„ ìˆìŒ.
    # ì—¬ê¸°ì„œëŠ” Chat Loop ì‚¬ìš©í•˜ë¯€ë¡œ ì´ ë…¸ë“œëŠ” ì‚¬ì‹¤ìƒ ì•ˆ ì“°ì´ê±°ë‚˜ ê°„ë‹¨í•œ ë¡œê·¸ìš©
    pass


async def exec_tag_set(state: GraphState):
    pass


# ----------------------------
# [5] Graph Build
# ----------------------------


def route_decision(state: GraphState):
    return state["intent_category"]


def build_graph():
    memory = MemorySaver()
    wf = StateGraph(GraphState)

    # ë…¸ë“œ ë“±ë¡
    wf.add_node("intent_router", intent_router)  # [ë³€ê²½] ingest_intent ëŒ€ì‹  Router ì‚¬ìš©

    wf.add_node("retrieve_rag", retrieve_rag)
    wf.add_node("generate_rag", generate_rag)

    wf.add_node("generate_chat", generate_chat)
    wf.add_node("sql_generate", sql_generate)

    wf.add_node("chat_tools_node", ToolNode(chat_tools_list))
    wf.add_node("sql_tools_node", ToolNode(sql_tools_list))

    # ì‹œì‘ -> ë¼ìš°í„°
    wf.add_edge(START, "intent_router")

    # ë¼ìš°í„° -> ë¶„ê¸°
    wf.add_conditional_edges(
        "intent_router",
        route_decision,
        {
            "sql_search": "sql_generate",
            "rag_search": "retrieve_rag",
            "chat": "generate_chat",
        },
    )

    # RAG ê²½ë¡œ
    wf.add_edge("retrieve_rag", "generate_rag")
    wf.add_edge("generate_rag", END)

    # Chat ê²½ë¡œ (Loop)
    wf.add_conditional_edges(
        "generate_chat", tools_condition, {"tools": "chat_tools_node", END: END}
    )
    wf.add_edge("chat_tools_node", "generate_chat")

    # SQL ê²½ë¡œ (Loop)
    wf.add_conditional_edges(
        "sql_generate", tools_condition, {"tools": "sql_tools_node", END: END}
    )
    wf.add_edge("sql_tools_node", "sql_generate")

    return wf.compile(checkpointer=memory)


app_graph = build_graph()


# ----------------------------
# [6] API Endpoint
# ----------------------------
class QueryRequest(BaseModel):
    question: str
    thread_id: str = "default_user"


@app.post("/ask")
async def ask(request: QueryRequest):
    print(f"\nQ : {request.question}")

    inputs = {"messages": [HumanMessage(content=request.question)]}
    config = RunnableConfig(
        configurable={"thread_id": request.thread_id}, recursion_limit=30
    )

    result = await app_graph.ainvoke(inputs, config=config)

    last_message = result["messages"][-1]
    final_answer = (
        last_message.content
        if isinstance(last_message, AIMessage)
        else "ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
    )

    return {
        "intent": result.get("intent_category"),
        "answer": final_answer,
    }


if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
